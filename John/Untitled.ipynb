{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'alpha_vantage'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-cf22fba2813d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0malpha_vantage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeseries\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTimeSeries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0malpha_vantage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtechindicators\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTechIndicators\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'alpha_vantage'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "from alpha_vantage.techindicators import TechIndicators\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "def get_data(symbol):\n",
    "\n",
    "    # Technical Indicators\n",
    "    ti = TechIndicators(key='YOUR_API_KEY', output_format='pandas')\n",
    "    sma, _ = ti.get_sma(symbol=symbol, interval='daily')\n",
    "    wma, _ = ti.get_wma(symbol=symbol, interval='daily')\n",
    "    ema, _ = ti.get_ema(symbol=symbol, interval='daily')\n",
    "    macd, _ = ti.get_macd(symbol=symbol, interval='daily')\n",
    "    stoch, _ = ti.get_stoch(symbol=symbol, interval='daily')\n",
    "    rsi, _ = ti.get_rsi(symbol=symbol, interval='daily')\n",
    "    adx, _ = ti.get_adx(symbol=symbol, interval='daily')\n",
    "    cci, _ = ti.get_cci(symbol=symbol, interval='daily')\n",
    "    aroon, _ = ti.get_aroon(symbol=symbol, interval='daily')\n",
    "    bbands, _ = ti.get_bbands(symbol=symbol, interval='daily')\n",
    "    ad, _ = ti.get_ad(symbol=symbol, interval='daily')\n",
    "    obv, _ = ti.get_obv(symbol=symbol, interval='daily')\n",
    "    mom, _ = ti.get_mom(symbol=symbol, interval='daily')\n",
    "    willr, _ = ti.get_willr(symbol=symbol, interval='daily')\n",
    "    tech_ind = pd.concat([sma, ema, macd, stoch, rsi, adx, cci, aroon, bbands, ad, obv, wma, mom, willr], axis=1)\n",
    "\n",
    "    ts = TimeSeries(key='YOUR_API_KEY', output_format='pandas')\n",
    "    close = ts.get_daily(symbol=symbol, outputsize='full')[0]['close']   # compact/full\n",
    "    direction = (close > close.shift()).astype(int)\n",
    "    target = direction.shift(-1).fillna(0).astype(int)\n",
    "    target.name = 'target'\n",
    "\n",
    "    data = pd.concat([tech_ind, close, target], axis=1)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_indicators(data, n):\n",
    "\n",
    "    hh = data['high'].rolling(n).max()\n",
    "    ll = data['low'].rolling(n).min()\n",
    "    up, dw = data['close'].diff(), -data['close'].diff()\n",
    "    up[up<0], dw[dw<0] = 0, 0\n",
    "    macd = data['close'].ewm(12).mean() - data['close'].ewm(26).mean()\n",
    "    macd_signal = macd.ewm(9).mean()\n",
    "    tp = (data['high'] + data['low'] + data['close']) / 3\n",
    "    tp_ma = tp.rolling(n).mean()\n",
    "    indicators = pd.DataFrame(data=0, index=data.index,\n",
    "                              columns=['sma', 'ema', 'momentum',\n",
    "                                       'sto_k', 'sto_d', 'rsi',\n",
    "                                       'macd', 'lw_r', 'a/d', 'cci'])\n",
    "    indicators['sma'] = data['close'].rolling(10).mean()\n",
    "    indicators['ema'] = data['close'].ewm(10).mean()\n",
    "    indicators['momentum'] = data['close'] - data['close'].shift(n)\n",
    "    indicators['sto_k'] = (data['close'] - ll) / (hh - ll) * 100\n",
    "    indicators['sto_d'] = indicators['sto_k'].rolling(n).mean()\n",
    "    indicators['rsi'] = 100 - 100 / (1 + up.rolling(14).mean() / dw.rolling(14).mean())\n",
    "    indicators['macd'] = macd - macd_signal\n",
    "    indicators['lw_r'] = (hh - data['close']) / (hh - ll) * 100\n",
    "    indicators['a/d'] = (data['high'] - data['close'].shift()) / (data['high'] - data['low'])\n",
    "    indicators['cci'] = (tp - tp_ma) / (0.015 * tp.rolling(n).apply(lambda x: np.std(x)))\n",
    "\n",
    "    return indicators\n",
    "\n",
    "\n",
    "def rebalance(unbalanced_data):\n",
    "\n",
    "    # Separate majority and minority classes\n",
    "    data_minority = unbalanced_data[unbalanced_data.target==0]\n",
    "    data_majority = unbalanced_data[unbalanced_data.target==1]\n",
    "\n",
    "    # Upsample minority class\n",
    "    n_samples = len(data_majority)\n",
    "    data_minority_upsampled = resample(data_minority, replace=True, n_samples=n_samples, random_state=5)\n",
    "\n",
    "    # Combine majority class with upsampled minority class\n",
    "    data_upsampled = pd.concat([data_majority, data_minority_upsampled])\n",
    "\n",
    "    data_upsampled.sort_index(inplace=True)\n",
    "\n",
    "    # Display new class counts\n",
    "    data_upsampled.target.value_counts()\n",
    "\n",
    "    return data_upsampled\n",
    "\n",
    "\n",
    "def normalize(x):\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    x_norm = scaler.fit_transform(x.values)\n",
    "    x_norm = pd.DataFrame(x_norm, index=x.index, columns=x.columns)\n",
    "\n",
    "    return x_norm\n",
    "\n",
    "\n",
    "def scores(models, X, y):\n",
    "\n",
    "    for model in models:\n",
    "        y_pred = model.predict(X)\n",
    "        acc = accuracy_score(y, y_pred)\n",
    "        f1 = f1_score(y, y_pred)\n",
    "        auc = roc_auc_score(y, y_pred)\n",
    "        print(\"Accuracy Score: {0:0.2f} %\".format(acc * 100))\n",
    "        print(\"F1 Score: {0:0.4f}\".format(f1))\n",
    "        print(\"Area Under ROC Curve Score: {0:0.4f}\".format(auc))\n",
    "\n",
    "\n",
    "symbol = 'SPX'  # S&P500\n",
    "data = get_data(symbol)\n",
    "data.tail(10)\n",
    "data.describe()\n",
    "ax = data['close'].plot(figsize=(9, 5))\n",
    "ax.set_ylabel(\"Price ($)\")\n",
    "ax.set_xlabel(\"Time\")\n",
    "plt.show()\n",
    "\n",
    "data_train = data['2011-01-01':'2017-01-01']\n",
    "data_train = rebalance(data_train)\n",
    "y = data_train.target\n",
    "X = data_train.drop('target', axis=1)\n",
    "X = normalize(X)\n",
    "data_val = data['2017-01-01':]\n",
    "y_val = data_val.target\n",
    "X_val = data_val.drop('target', axis=1)\n",
    "X_val = normalize(X_val)\n",
    "\n",
    "# Machine Learning\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/6, shuffle=False)\n",
    "\n",
    "models = [GaussianNB(),\n",
    "          SVC(random_state=5),\n",
    "          RandomForestClassifier(random_state=5),\n",
    "          MLPClassifier(random_state=5)]\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "scores(models, X_test, y_test)\n",
    "\n",
    "# Grid search\n",
    "grid_data = [[{'kernel': ['poly'], 'degree': [1, 2, 3, 4], 'C': [0.1, 1, 10, 100], 'random_state': [5]},\n",
    "              {'kernel': ['rbf', 'sigmoid'], 'C': [0.1, 1, 10, 100], 'random_state': [5]}],\n",
    "              {'n_estimators': [10, 50, 100],\n",
    "               'criterion': ['gini', 'entropy'],\n",
    "               'max_depth': [None, 10, 50, 100],\n",
    "               'min_samples_split': [2, 5, 10],\n",
    "               'random_state': [5]},\n",
    "              {'hidden_layer_sizes': [10, 50, 100],\n",
    "               'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "               'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "               'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "               'max_iter': [200, 400, 800],\n",
    "               'random_state': [5]}]\n",
    "models_grid = list()\n",
    "for i in range(3):\n",
    "    grid = GridSearchCV(models[i], grid_data[i], scoring='f1').fit(X_train, y_train)\n",
    "    print(grid.best_params_)\n",
    "    model = grid.best_estimator_\n",
    "    models_grid.append(model)\n",
    "scores(models_grid, X_test, y_test)\n",
    "\n",
    "# Validation data\n",
    "scores(models_grid, X_val, y_val)\n",
    "\n",
    "# Trading system\n",
    "rf_model = models_grid[0]\n",
    "y_pred = rf_model.predict(X_val)\n",
    "mask = y_pred.copy()\n",
    "np.place(mask, y_pred==0, -1)\n",
    "mask = np.roll(mask, 1)\n",
    "data_returns = data['close'].diff()\n",
    "data_returns = data_returns[X_val.index]\n",
    "model_returns = mask * data_returns\n",
    "model_cum = model_returns.cumsum()\n",
    "equity = model_returns.sum()\n",
    "start_close = data[\"close\"][X_val.index[0]]\n",
    "performance = equity / start_close * 100\n",
    "ax = model_returns.plot(figsize=(9, 5))\n",
    "ax.set_ylabel(\"Returns ($)\")\n",
    "ax.set_xlabel(\"Time\")\n",
    "plt.show()\n",
    "ax = model_cum.plot(figsize=(9, 5))\n",
    "ax.set_ylabel(\"Cummulative returns ($)\")\n",
    "ax.set_xlabel(\"Time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
